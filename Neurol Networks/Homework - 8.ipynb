{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fca457c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Make better use of Jupyter Notebook cell width\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37935a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d460cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7e40dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e293153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop with next function:\n",
    "\n",
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eed4da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dino': 0, 'dragon': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "942e1672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = train_gen.flow_from_directory(\n",
    "    './test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39be97c",
   "metadata": {},
   "source": [
    "# For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "- You need to develop the model with following structure:\n",
    "\n",
    "- The shape for input should be (150, 150, 3)\n",
    "- Next, create a convolutional layer (Conv2D):\n",
    "- Use 32 filters\n",
    "- Kernel size should be (3, 3) (that's the size of the filter)\n",
    "- Use 'relu' as activation\n",
    "- Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "- Set the pooling size to (2, 2)\n",
    "- Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "- Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "- Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "- The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "- As optimizer use SGD with the following parameters:\n",
    "\n",
    "- SGD(lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d22a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model:\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use SGD optimizer with learning rate of 0.002 and momentum of 0.8\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde050a4",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "\n",
    "- Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- Note: since we specify an activation for the output layer, we don't need to set from_logits=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1912853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer is binary_crossentropy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5315fcd",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "- What's the total number of parameters of the model? You can use the summary method for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a78d3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe250ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer is 11,215,873!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee02e6",
   "metadata": {},
   "source": [
    "# Generators and Training\n",
    "- For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "- ImageDataGenerator(rescale=1./255)\n",
    "- We don't need to do any additional pre-processing for the images.\n",
    "- When reading the data from train/test directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "- Use batch_size=20\n",
    "- Use shuffle=True for both training and test sets.\n",
    "- For training use .fit() with the following params:\n",
    "\n",
    "- model.fit(\n",
    "-    train_generator,\n",
    "-    epochs=10,\n",
    "-    validation_data=test_generator\n",
    "- )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9264f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 13:04:02.179143: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-02-26 13:04:02.847408: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-26 13:04:02.848431: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-26 13:04:02.848471: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-02-26 13:04:02.849500: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-26 13:04:02.849617: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 11s 109ms/step - loss: 0.6673 - accuracy: 0.6255 - val_loss: 0.6147 - val_accuracy: 0.6193\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.5360 - accuracy: 0.7597 - val_loss: 0.4610 - val_accuracy: 0.8325\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.4319 - accuracy: 0.8156 - val_loss: 0.4833 - val_accuracy: 0.7716\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3693 - accuracy: 0.8513 - val_loss: 0.3810 - val_accuracy: 0.8223\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3328 - accuracy: 0.8588 - val_loss: 0.3414 - val_accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3007 - accuracy: 0.8858 - val_loss: 0.3321 - val_accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 0.2828 - accuracy: 0.8833 - val_loss: 0.3929 - val_accuracy: 0.8173\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2467 - accuracy: 0.9109 - val_loss: 0.3047 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.2345 - accuracy: 0.9153 - val_loss: 0.2993 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.1956 - accuracy: 0.9335 - val_loss: 0.2946 - val_accuracy: 0.8731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8180657940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training parameters\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 20,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Creating validation(test) parameters:\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 20,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# fitting the model:\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70afa10",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "- What is the median of training accuracy for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd09e2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710790276527405"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(model.history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabb230",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "- What is the standard deviation of training loss for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7b4dfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14017966098234794"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0fdbf",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "- For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "- Add the following augmentations to your training data generator:\n",
    "\n",
    "- rotation_range=40,\n",
    "- width_shift_range=0.2,\n",
    "- height_shift_range=0.2,\n",
    "- shear_range=0.2,\n",
    "- zoom_range=0.2,\n",
    "- horizontal_flip=True,\n",
    "- fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea9d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b43cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 15s 310ms/step - loss: 0.2876 - accuracy: 0.8745 - val_loss: 0.5714 - val_accuracy: 0.7766\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 0.2760 - accuracy: 0.8921 - val_loss: 0.6115 - val_accuracy: 0.7741\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 0.2936 - accuracy: 0.8770 - val_loss: 0.5188 - val_accuracy: 0.8096\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 0.3073 - accuracy: 0.8777 - val_loss: 0.3088 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 0.2957 - accuracy: 0.8764 - val_loss: 0.3941 - val_accuracy: 0.8452\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 0.2930 - accuracy: 0.8802 - val_loss: 0.3515 - val_accuracy: 0.8503\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 15s 304ms/step - loss: 0.2942 - accuracy: 0.8770 - val_loss: 0.4882 - val_accuracy: 0.8046\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 0.2846 - accuracy: 0.8846 - val_loss: 0.3965 - val_accuracy: 0.8452\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 0.2847 - accuracy: 0.8915 - val_loss: 0.3255 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 0.2892 - accuracy: 0.8839 - val_loss: 0.4474 - val_accuracy: 0.8046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81b41442b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create image generator for train data and also augment the images:\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 32,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './test/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size= 32,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# model training with augmentation:\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b88384",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "- Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "- What is the mean of test loss for all the epochs for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caba3798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44137109220027926"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d3edc",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "- What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6898d5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8345177650451661"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.history.history['val_accuracy'][5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bee4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d9936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
